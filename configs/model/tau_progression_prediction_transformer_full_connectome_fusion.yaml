_target_: src.models.tau_progression_prediction_transformer_full_connectome_fusion.TransformerModelFullConnFusion

# Given
d_in: 203
d_out: 200

# Tunable
d_model: 128
d_hid: 100
max_len: 10
n_encoder_heads: 2
n_encoder_layers: 2
lr: 0.001
activation: "gelu"
transformer_dropout: 0.2
dropout: 0.2
